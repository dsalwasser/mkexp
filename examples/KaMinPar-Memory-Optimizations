#!/bin/bash

# This is a template for a KaMinPar memory optimization experiment configuration file.

# Define the reference KaMinPar algorithm without memory optimizations.
#
DefineAlgorithmVersion pKaMinPar-Reference pKaMinPar origin/main-upstream

# Defines two algorithm:
# - KaMinPar without memory optimizations
# - KaMinPar with memory optimizations
#
DefineAlgorithm Reference pKaMinPar-Reference --p-deep-initial-partitioning-mode sequential --rearrange-by deg-buckets
DefineAlgorithm Memory-Optimizations pKaMinPar --p-deep-initial-partitioning-mode sequential --node-order implicit-deg-buckets -P memory

# Pick a system for which the jobfiles should be generated:
#
System Generic
# System Generic                # any Linux system
# System i10                    # i10 compute servers, run experiment via "exclusive"
# System i10-Nonexclusive       # i10 compute servers, run without "exclusive"
# System i10-Parallel           # i10 + GNU Parallel (only use for sequential runs and if you don't need precise running times)
# System HoreKa-TBB             # HoreKa with MPI only / MPI+TBB
# System HoreKa-OMP             # HoreKa with MPI only / MPI+OpenMP
# System SuperMUC               # SuperMUC with MPI only / MPI+TBB
# System SuperMUC-SlotScheduler # SuperMUC for shared-memory or sequential jobs, that are executed in parallel on multiple jobs by a job scheduler

# If you want to run this experiment on SuperMUC, provide additional parameters:
#
# Username <username>   # your SSH username for SuperMUC file transfer
# Project <project>     # your SuperMUC project
# Partition <partition> # *OPTIONAL*, if not set, job partition will be either micro, general or large, depending on the number of nodes

# Pick a "call wrapper" that should be used to invoke the partitioners.
#
MPI none
# MPI none    # do not run with mpirun etc.
# MPI OpenMPI # run with mpirun
# MPI IMPI    # run with Intel MPI (SuperMUC only)
# MPI taskset # do not run with mpirun etc., but use taskset to limit CPU affinity

ExperimentMemoryOptimizations() {
    Algorithms Reference Memory-Optimizations

    Ks 8 37 91 128 1000 # Partition into 8, 37, 91, 128 and 1000 blocks
    Seeds 1 2 3 4 5 # Perform repetitions with seeds 1, 2, 3, 4 and 5
    Threads 1x1x4 1x1x64 # Run with 4 and 64 threads
    #       | | +-- number of threads
    #       | +-- number of MPI processes
    #       +-- number of compute nodes

    # Timelimit 1:00:00 # Abort experiment after one hour (optional)
    # TimelimitPerInstance 30:00 # Abort one run after 30 minutes (optional)

    Graphs /path/to/benchmark/set/ # Partition all graphs contained in some directory
}
